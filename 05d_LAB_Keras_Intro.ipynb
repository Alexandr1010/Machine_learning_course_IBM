{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-win_amd64.whl (909 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.34.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: wrapt, termcolor\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=713d8174db74b529b5f227d5e0fb49d9716593c0c94b9a42925d888d9e27c037\n",
      "  Stored in directory: c:\\users\\alexb\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=b44c10ec90a65ffc3a01e0e44adf3b76d2be62be609304b09f6ff5fbedc78a71\n",
      "  Stored in directory: c:\\users\\alexb\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built wrapt termcolor\n",
      "Installing collected packages: astunparse, grpcio, protobuf, gast, tensorboard-plugin-wit, absl-py, tensorboard-data-server, oauthlib, requests-oauthlib, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, google-auth-oauthlib, markdown, tensorboard, keras-nightly, opt-einsum, tensorflow-estimator, flatbuffers, keras-preprocessing, wrapt, google-pasta, h5py, termcolor, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.34.0 google-auth-oauthlib-0.4.5 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 wrapt-1.12.1\n",
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find conda environment: tf\n",
      "You can list all discoverable environments with `conda info --envs`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!conda create -n tf tensorflow\n",
    "#!conda activate tf\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9</td>\n",
       "      <td>171</td>\n",
       "      <td>110</td>\n",
       "      <td>24</td>\n",
       "      <td>240</td>\n",
       "      <td>45.4</td>\n",
       "      <td>0.721</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.258</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>255</td>\n",
       "      <td>47.9</td>\n",
       "      <td>0.259</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>205</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.591</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.649</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "43                9                     171             110              24   \n",
       "463               5                      88              78              30   \n",
       "335               0                     165              76              43   \n",
       "685               2                     129              74              26   \n",
       "637               2                      94              76              18   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "43       240  45.4              0.721   54             1  \n",
       "463        0  27.6              0.258   37             0  \n",
       "335      255  47.9              0.259   26             0  \n",
       "685      205  33.2              0.591   25             0  \n",
       "637       66  31.6              0.649   23             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.776\n",
      "roc-auc is 0.827\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    sns.set_style('dark')\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0984 - accuracy: 0.3455 - val_loss: 1.0496 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0569 - accuracy: 0.3455 - val_loss: 1.0116 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0186 - accuracy: 0.3455 - val_loss: 0.9766 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9834 - accuracy: 0.3455 - val_loss: 0.9446 - val_accuracy: 0.3594\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9510 - accuracy: 0.3455 - val_loss: 0.9154 - val_accuracy: 0.3594\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9215 - accuracy: 0.3455 - val_loss: 0.8888 - val_accuracy: 0.3594\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8945 - accuracy: 0.3472 - val_loss: 0.8647 - val_accuracy: 0.3594\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.3455 - val_loss: 0.8427 - val_accuracy: 0.3594\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8476 - accuracy: 0.3490 - val_loss: 0.8229 - val_accuracy: 0.3542\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8273 - accuracy: 0.3438 - val_loss: 0.8050 - val_accuracy: 0.3438\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8090 - accuracy: 0.3507 - val_loss: 0.7888 - val_accuracy: 0.3333\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7923 - accuracy: 0.3490 - val_loss: 0.7743 - val_accuracy: 0.3385\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7773 - accuracy: 0.3559 - val_loss: 0.7612 - val_accuracy: 0.3438\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7637 - accuracy: 0.3490 - val_loss: 0.7494 - val_accuracy: 0.3542\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7515 - accuracy: 0.3646 - val_loss: 0.7388 - val_accuracy: 0.3698\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7404 - accuracy: 0.3559 - val_loss: 0.7293 - val_accuracy: 0.3854\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7304 - accuracy: 0.3733 - val_loss: 0.7207 - val_accuracy: 0.4167\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7214 - accuracy: 0.3872 - val_loss: 0.7130 - val_accuracy: 0.4271\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.4288 - val_loss: 0.7061 - val_accuracy: 0.4375\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.4549 - val_loss: 0.6999 - val_accuracy: 0.4792\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.4774 - val_loss: 0.6942 - val_accuracy: 0.4948\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5122 - val_loss: 0.6892 - val_accuracy: 0.5573\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5434 - val_loss: 0.6846 - val_accuracy: 0.5938\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5764 - val_loss: 0.6804 - val_accuracy: 0.6094\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5868 - val_loss: 0.6767 - val_accuracy: 0.6354\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.6042 - val_loss: 0.6733 - val_accuracy: 0.6406\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.6233 - val_loss: 0.6702 - val_accuracy: 0.6458\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6354 - val_loss: 0.6674 - val_accuracy: 0.6562\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6493 - val_loss: 0.6648 - val_accuracy: 0.6510\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6615 - val_loss: 0.6625 - val_accuracy: 0.6562\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6667 - val_loss: 0.6603 - val_accuracy: 0.6562\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6719 - val_loss: 0.6583 - val_accuracy: 0.6458\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6736 - val_loss: 0.6565 - val_accuracy: 0.6458\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6753 - val_loss: 0.6548 - val_accuracy: 0.6458\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6701 - val_loss: 0.6533 - val_accuracy: 0.6406\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6736 - val_loss: 0.6518 - val_accuracy: 0.6354\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6667 - val_loss: 0.6505 - val_accuracy: 0.6354\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.6667 - val_loss: 0.6492 - val_accuracy: 0.6354\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6684 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.6667 - val_loss: 0.6469 - val_accuracy: 0.6406\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6667 - val_loss: 0.6458 - val_accuracy: 0.6406\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6649 - val_loss: 0.6448 - val_accuracy: 0.6458\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6632 - val_loss: 0.6439 - val_accuracy: 0.6458\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6615 - val_loss: 0.6430 - val_accuracy: 0.6458\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6615 - val_loss: 0.6421 - val_accuracy: 0.6458\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.6615 - val_loss: 0.6413 - val_accuracy: 0.6458\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6615 - val_loss: 0.6405 - val_accuracy: 0.6458\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6615 - val_loss: 0.6397 - val_accuracy: 0.6458\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6615 - val_loss: 0.6389 - val_accuracy: 0.6458\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6615 - val_loss: 0.6382 - val_accuracy: 0.6458\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6615 - val_loss: 0.6375 - val_accuracy: 0.6458\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6615 - val_loss: 0.6368 - val_accuracy: 0.6458\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6615 - val_loss: 0.6361 - val_accuracy: 0.6458\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6615 - val_loss: 0.6355 - val_accuracy: 0.6458\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6615 - val_loss: 0.6348 - val_accuracy: 0.6406\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6615 - val_loss: 0.6342 - val_accuracy: 0.6406\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6615 - val_loss: 0.6336 - val_accuracy: 0.6406\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6597 - val_loss: 0.6330 - val_accuracy: 0.6406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6597 - val_loss: 0.6324 - val_accuracy: 0.6406\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6597 - val_loss: 0.6318 - val_accuracy: 0.6406\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6597 - val_loss: 0.6312 - val_accuracy: 0.6406\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6597 - val_loss: 0.6306 - val_accuracy: 0.6406\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6597 - val_loss: 0.6300 - val_accuracy: 0.6406\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6597 - val_loss: 0.6294 - val_accuracy: 0.6406\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6597 - val_loss: 0.6288 - val_accuracy: 0.6406\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6597 - val_loss: 0.6283 - val_accuracy: 0.6406\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6615 - val_loss: 0.6277 - val_accuracy: 0.6406\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6615 - val_loss: 0.6271 - val_accuracy: 0.6406\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6615 - val_loss: 0.6266 - val_accuracy: 0.6406\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.6615 - val_loss: 0.6260 - val_accuracy: 0.6406\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6615 - val_loss: 0.6255 - val_accuracy: 0.6406\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6615 - val_loss: 0.6249 - val_accuracy: 0.6406\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6615 - val_loss: 0.6244 - val_accuracy: 0.6406\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6615 - val_loss: 0.6238 - val_accuracy: 0.6406\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6615 - val_loss: 0.6233 - val_accuracy: 0.6406\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6615 - val_loss: 0.6227 - val_accuracy: 0.6406\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6615 - val_loss: 0.6222 - val_accuracy: 0.6406\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6615 - val_loss: 0.6216 - val_accuracy: 0.6406\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6615 - val_loss: 0.6211 - val_accuracy: 0.6406\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6615 - val_loss: 0.6206 - val_accuracy: 0.6406\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6597 - val_loss: 0.6200 - val_accuracy: 0.6406\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6615 - val_loss: 0.6195 - val_accuracy: 0.6406\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6615 - val_loss: 0.6190 - val_accuracy: 0.6406\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6597 - val_loss: 0.6184 - val_accuracy: 0.6406\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6597 - val_loss: 0.6179 - val_accuracy: 0.6406\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6597 - val_loss: 0.6173 - val_accuracy: 0.6406\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6597 - val_loss: 0.6168 - val_accuracy: 0.6406\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6597 - val_loss: 0.6163 - val_accuracy: 0.6406\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6597 - val_loss: 0.6158 - val_accuracy: 0.6406\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6615 - val_loss: 0.6152 - val_accuracy: 0.6406\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6615 - val_loss: 0.6147 - val_accuracy: 0.6406\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.6597 - val_loss: 0.6142 - val_accuracy: 0.6406\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6597 - val_loss: 0.6136 - val_accuracy: 0.6406\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6597 - val_loss: 0.6131 - val_accuracy: 0.6406\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6615 - val_loss: 0.6126 - val_accuracy: 0.6406\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6615 - val_loss: 0.6121 - val_accuracy: 0.6406\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6649 - val_loss: 0.6116 - val_accuracy: 0.6406\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6649 - val_loss: 0.6110 - val_accuracy: 0.6406\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6649 - val_loss: 0.6105 - val_accuracy: 0.6406\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6649 - val_loss: 0.6100 - val_accuracy: 0.6406\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6649 - val_loss: 0.6095 - val_accuracy: 0.6406\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6649 - val_loss: 0.6090 - val_accuracy: 0.6406\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6649 - val_loss: 0.6084 - val_accuracy: 0.6406\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6649 - val_loss: 0.6079 - val_accuracy: 0.6406\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6649 - val_loss: 0.6074 - val_accuracy: 0.6406\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6649 - val_loss: 0.6069 - val_accuracy: 0.6406\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6649 - val_loss: 0.6064 - val_accuracy: 0.6406\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6649 - val_loss: 0.6059 - val_accuracy: 0.6406\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6649 - val_loss: 0.6054 - val_accuracy: 0.6406\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6649 - val_loss: 0.6049 - val_accuracy: 0.6458\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6649 - val_loss: 0.6044 - val_accuracy: 0.6458\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6667 - val_loss: 0.6039 - val_accuracy: 0.6458\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6667 - val_loss: 0.6033 - val_accuracy: 0.6458\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6684 - val_loss: 0.6028 - val_accuracy: 0.6458\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6701 - val_loss: 0.6023 - val_accuracy: 0.6458\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6701 - val_loss: 0.6018 - val_accuracy: 0.6458\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6701 - val_loss: 0.6013 - val_accuracy: 0.6458\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6701 - val_loss: 0.6008 - val_accuracy: 0.6510\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6701 - val_loss: 0.6003 - val_accuracy: 0.6510\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.6701 - val_loss: 0.5998 - val_accuracy: 0.6510\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6701 - val_loss: 0.5994 - val_accuracy: 0.6510\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6701 - val_loss: 0.5989 - val_accuracy: 0.6510\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6701 - val_loss: 0.5984 - val_accuracy: 0.6510\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6736 - val_loss: 0.5979 - val_accuracy: 0.6510\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6736 - val_loss: 0.5974 - val_accuracy: 0.6510\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6736 - val_loss: 0.5969 - val_accuracy: 0.6510\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6736 - val_loss: 0.5964 - val_accuracy: 0.6510\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6736 - val_loss: 0.5959 - val_accuracy: 0.6510\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6736 - val_loss: 0.5954 - val_accuracy: 0.6510\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6736 - val_loss: 0.5949 - val_accuracy: 0.6510\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6736 - val_loss: 0.5945 - val_accuracy: 0.6510\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6753 - val_loss: 0.5940 - val_accuracy: 0.6510\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.6771 - val_loss: 0.5935 - val_accuracy: 0.6510\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6771 - val_loss: 0.5930 - val_accuracy: 0.6510\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6823 - val_loss: 0.5925 - val_accuracy: 0.6562\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6806 - val_loss: 0.5921 - val_accuracy: 0.6562\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.6823 - val_loss: 0.5916 - val_accuracy: 0.6562\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6840 - val_loss: 0.5911 - val_accuracy: 0.6562\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6840 - val_loss: 0.5906 - val_accuracy: 0.6615\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.6840 - val_loss: 0.5901 - val_accuracy: 0.6615\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6858 - val_loss: 0.5897 - val_accuracy: 0.6615\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.6858 - val_loss: 0.5892 - val_accuracy: 0.6615\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6858 - val_loss: 0.5887 - val_accuracy: 0.6615\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6858 - val_loss: 0.5883 - val_accuracy: 0.6667\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.6858 - val_loss: 0.5878 - val_accuracy: 0.6667\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.6910 - val_loss: 0.5873 - val_accuracy: 0.6667\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.6910 - val_loss: 0.5869 - val_accuracy: 0.6667\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.6910 - val_loss: 0.5864 - val_accuracy: 0.6667\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.6910 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.6910 - val_loss: 0.5855 - val_accuracy: 0.6719\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.6910 - val_loss: 0.5850 - val_accuracy: 0.6719\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.6910 - val_loss: 0.5846 - val_accuracy: 0.6719\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.6927 - val_loss: 0.5841 - val_accuracy: 0.6771\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.6927 - val_loss: 0.5836 - val_accuracy: 0.6771\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6944 - val_loss: 0.5832 - val_accuracy: 0.6771\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.6910 - val_loss: 0.5827 - val_accuracy: 0.6771\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.6927 - val_loss: 0.5823 - val_accuracy: 0.6823\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6927 - val_loss: 0.5818 - val_accuracy: 0.6823\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.6979 - val_loss: 0.5814 - val_accuracy: 0.6823\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.6997 - val_loss: 0.5809 - val_accuracy: 0.6823\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6997 - val_loss: 0.5805 - val_accuracy: 0.6875\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.6997 - val_loss: 0.5800 - val_accuracy: 0.6875\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.6997 - val_loss: 0.5796 - val_accuracy: 0.6927\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.6997 - val_loss: 0.5791 - val_accuracy: 0.6979\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.6979 - val_loss: 0.5787 - val_accuracy: 0.6979\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.6979 - val_loss: 0.5783 - val_accuracy: 0.6979\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.6944 - val_loss: 0.5778 - val_accuracy: 0.6979\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.6962 - val_loss: 0.5774 - val_accuracy: 0.6979\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.6979 - val_loss: 0.5769 - val_accuracy: 0.7031\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.6997 - val_loss: 0.5765 - val_accuracy: 0.7083\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.6997 - val_loss: 0.5761 - val_accuracy: 0.7083\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.6997 - val_loss: 0.5756 - val_accuracy: 0.7083\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.6997 - val_loss: 0.5752 - val_accuracy: 0.7083\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.6997 - val_loss: 0.5748 - val_accuracy: 0.7083\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7014 - val_loss: 0.5743 - val_accuracy: 0.7083\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.6997 - val_loss: 0.5739 - val_accuracy: 0.7083\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7014 - val_loss: 0.5735 - val_accuracy: 0.7083\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7014 - val_loss: 0.5730 - val_accuracy: 0.7083\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7014 - val_loss: 0.5726 - val_accuracy: 0.7083\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7031 - val_loss: 0.5722 - val_accuracy: 0.7135\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7031 - val_loss: 0.5718 - val_accuracy: 0.7135\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7031 - val_loss: 0.5713 - val_accuracy: 0.7135\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7031 - val_loss: 0.5709 - val_accuracy: 0.7135\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7031 - val_loss: 0.5705 - val_accuracy: 0.7135\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7031 - val_loss: 0.5701 - val_accuracy: 0.7135\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7031 - val_loss: 0.5697 - val_accuracy: 0.7135\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7031 - val_loss: 0.5693 - val_accuracy: 0.7135\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7031 - val_loss: 0.5688 - val_accuracy: 0.7135\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7031 - val_loss: 0.5684 - val_accuracy: 0.7135\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7031 - val_loss: 0.5680 - val_accuracy: 0.7188\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7031 - val_loss: 0.5676 - val_accuracy: 0.7135\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7031 - val_loss: 0.5672 - val_accuracy: 0.7135\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7031 - val_loss: 0.5668 - val_accuracy: 0.7135\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7031 - val_loss: 0.5664 - val_accuracy: 0.7135\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7031 - val_loss: 0.5660 - val_accuracy: 0.7135\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7014 - val_loss: 0.5656 - val_accuracy: 0.7135\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7031 - val_loss: 0.5652 - val_accuracy: 0.7135\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7031 - val_loss: 0.5648 - val_accuracy: 0.7135\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7031 - val_loss: 0.5644 - val_accuracy: 0.7135\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7031 - val_loss: 0.5640 - val_accuracy: 0.7135\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3613574 ],\n",
       "       [0.37822694],\n",
       "       [0.317191  ],\n",
       "       [0.26521695],\n",
       "       [0.3177224 ],\n",
       "       [0.41089374],\n",
       "       [0.2328946 ],\n",
       "       [0.2522663 ],\n",
       "       [0.5426442 ],\n",
       "       [0.3049148 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.714\n",
      "roc-auc is 0.807\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2e729609f70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7031 - val_loss: 0.5636 - val_accuracy: 0.7135\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7031 - val_loss: 0.5632 - val_accuracy: 0.7135\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7049 - val_loss: 0.5628 - val_accuracy: 0.7135\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7049 - val_loss: 0.5624 - val_accuracy: 0.7135\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7066 - val_loss: 0.5620 - val_accuracy: 0.7135\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7083 - val_loss: 0.5616 - val_accuracy: 0.7083\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7101 - val_loss: 0.5612 - val_accuracy: 0.7083\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7101 - val_loss: 0.5608 - val_accuracy: 0.7083\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7118 - val_loss: 0.5605 - val_accuracy: 0.7135\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7135 - val_loss: 0.5601 - val_accuracy: 0.7135\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7118 - val_loss: 0.5597 - val_accuracy: 0.7135\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7170 - val_loss: 0.5593 - val_accuracy: 0.7188\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7170 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7205 - val_loss: 0.5585 - val_accuracy: 0.7188\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7222 - val_loss: 0.5582 - val_accuracy: 0.7188\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7205 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7205 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7222 - val_loss: 0.5570 - val_accuracy: 0.7188\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7205 - val_loss: 0.5567 - val_accuracy: 0.7188\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7205 - val_loss: 0.5563 - val_accuracy: 0.7188\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7222 - val_loss: 0.5559 - val_accuracy: 0.7240\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7240 - val_loss: 0.5555 - val_accuracy: 0.7240\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7222 - val_loss: 0.5552 - val_accuracy: 0.7292\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7222 - val_loss: 0.5548 - val_accuracy: 0.7344\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7257 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7274 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7274 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7309 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7309 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7309 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7309 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7309 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7326 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7326 - val_loss: 0.5512 - val_accuracy: 0.7448\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7326 - val_loss: 0.5509 - val_accuracy: 0.7448\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7344 - val_loss: 0.5505 - val_accuracy: 0.7448\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7344 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7361 - val_loss: 0.5498 - val_accuracy: 0.7552\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7361 - val_loss: 0.5495 - val_accuracy: 0.7552\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7361 - val_loss: 0.5491 - val_accuracy: 0.7552\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7361 - val_loss: 0.5488 - val_accuracy: 0.7552\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7361 - val_loss: 0.5484 - val_accuracy: 0.7552\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7344 - val_loss: 0.5481 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7361 - val_loss: 0.5478 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7361 - val_loss: 0.5474 - val_accuracy: 0.7552\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7344 - val_loss: 0.5471 - val_accuracy: 0.7552\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7344 - val_loss: 0.5467 - val_accuracy: 0.7552\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7344 - val_loss: 0.5464 - val_accuracy: 0.7552\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7344 - val_loss: 0.5461 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7361 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7361 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7344 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7378 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7361 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7361 - val_loss: 0.5441 - val_accuracy: 0.7604\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7396 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7413 - val_loss: 0.5435 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7413 - val_loss: 0.5431 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7413 - val_loss: 0.5428 - val_accuracy: 0.7656\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7431 - val_loss: 0.5425 - val_accuracy: 0.7708\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7431 - val_loss: 0.5422 - val_accuracy: 0.7708\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7431 - val_loss: 0.5419 - val_accuracy: 0.7708\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7431 - val_loss: 0.5415 - val_accuracy: 0.7760\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7448 - val_loss: 0.5412 - val_accuracy: 0.7760\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7465 - val_loss: 0.5409 - val_accuracy: 0.7760\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7483 - val_loss: 0.5406 - val_accuracy: 0.7760\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7500 - val_loss: 0.5403 - val_accuracy: 0.7760\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7500 - val_loss: 0.5400 - val_accuracy: 0.7760\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7483 - val_loss: 0.5397 - val_accuracy: 0.7760\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7500 - val_loss: 0.5394 - val_accuracy: 0.7760\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7483 - val_loss: 0.5391 - val_accuracy: 0.7760\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7465 - val_loss: 0.5388 - val_accuracy: 0.7812\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7483 - val_loss: 0.5385 - val_accuracy: 0.7812\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7465 - val_loss: 0.5382 - val_accuracy: 0.7812\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7448 - val_loss: 0.5379 - val_accuracy: 0.7865\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7465 - val_loss: 0.5376 - val_accuracy: 0.7812\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7483 - val_loss: 0.5373 - val_accuracy: 0.7812\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5370 - val_accuracy: 0.7760\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7465 - val_loss: 0.5367 - val_accuracy: 0.7760\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7465 - val_loss: 0.5364 - val_accuracy: 0.7760\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7483 - val_loss: 0.5361 - val_accuracy: 0.7760\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7483 - val_loss: 0.5358 - val_accuracy: 0.7760\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7500 - val_loss: 0.5355 - val_accuracy: 0.7760\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7500 - val_loss: 0.5352 - val_accuracy: 0.7812\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7500 - val_loss: 0.5350 - val_accuracy: 0.7812\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.5347 - val_accuracy: 0.7865\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7500 - val_loss: 0.5344 - val_accuracy: 0.7865\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7517 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7535 - val_loss: 0.5338 - val_accuracy: 0.7812\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7535 - val_loss: 0.5335 - val_accuracy: 0.7812\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7569 - val_loss: 0.5333 - val_accuracy: 0.7812\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7569 - val_loss: 0.5330 - val_accuracy: 0.7812\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7569 - val_loss: 0.5327 - val_accuracy: 0.7812\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7569 - val_loss: 0.5324 - val_accuracy: 0.7812\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7552 - val_loss: 0.5322 - val_accuracy: 0.7812\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7552 - val_loss: 0.5319 - val_accuracy: 0.7812\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7552 - val_loss: 0.5316 - val_accuracy: 0.7812\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7552 - val_loss: 0.5313 - val_accuracy: 0.7812\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7552 - val_loss: 0.5311 - val_accuracy: 0.7812\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7552 - val_loss: 0.5308 - val_accuracy: 0.7812\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7552 - val_loss: 0.5305 - val_accuracy: 0.7812\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7569 - val_loss: 0.5303 - val_accuracy: 0.7812\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7587 - val_loss: 0.5300 - val_accuracy: 0.7812\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7587 - val_loss: 0.5298 - val_accuracy: 0.7812\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7604 - val_loss: 0.5295 - val_accuracy: 0.7812\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7604 - val_loss: 0.5292 - val_accuracy: 0.7812\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7604 - val_loss: 0.5290 - val_accuracy: 0.7812\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7622 - val_loss: 0.5287 - val_accuracy: 0.7812\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7639 - val_loss: 0.5285 - val_accuracy: 0.7812\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.7812\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7622 - val_loss: 0.5280 - val_accuracy: 0.7760\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7622 - val_loss: 0.5277 - val_accuracy: 0.7760\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7622 - val_loss: 0.5275 - val_accuracy: 0.7760\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7639 - val_loss: 0.5272 - val_accuracy: 0.7760\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7639 - val_loss: 0.5270 - val_accuracy: 0.7760\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7639 - val_loss: 0.5267 - val_accuracy: 0.7760\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7639 - val_loss: 0.5265 - val_accuracy: 0.7760\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7639 - val_loss: 0.5262 - val_accuracy: 0.7760\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7639 - val_loss: 0.5260 - val_accuracy: 0.7812\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7639 - val_loss: 0.5257 - val_accuracy: 0.7812\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7656 - val_loss: 0.5255 - val_accuracy: 0.7812\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7656 - val_loss: 0.5253 - val_accuracy: 0.7812\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7812\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7656 - val_loss: 0.5248 - val_accuracy: 0.7812\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7656 - val_loss: 0.5245 - val_accuracy: 0.7812\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7656 - val_loss: 0.5243 - val_accuracy: 0.7812\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7656 - val_loss: 0.5241 - val_accuracy: 0.7812\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7656 - val_loss: 0.5238 - val_accuracy: 0.7812\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7656 - val_loss: 0.5236 - val_accuracy: 0.7812\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7639 - val_loss: 0.5234 - val_accuracy: 0.7812\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7656 - val_loss: 0.5231 - val_accuracy: 0.7812\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7639 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7639 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7639 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7865\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7656 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7639 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7639 - val_loss: 0.5207 - val_accuracy: 0.7812\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7639 - val_loss: 0.5205 - val_accuracy: 0.7812\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7656 - val_loss: 0.5203 - val_accuracy: 0.7812\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7656 - val_loss: 0.5200 - val_accuracy: 0.7812\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7656 - val_loss: 0.5198 - val_accuracy: 0.7812\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7656 - val_loss: 0.5196 - val_accuracy: 0.7812\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7674 - val_loss: 0.5194 - val_accuracy: 0.7812\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7691 - val_loss: 0.5192 - val_accuracy: 0.7812\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7812\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7812\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7812\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7726 - val_loss: 0.5182 - val_accuracy: 0.7812\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7726 - val_loss: 0.5178 - val_accuracy: 0.7865\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7726 - val_loss: 0.5176 - val_accuracy: 0.7865\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7726 - val_loss: 0.5174 - val_accuracy: 0.7865\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7726 - val_loss: 0.5172 - val_accuracy: 0.7865\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7743 - val_loss: 0.5170 - val_accuracy: 0.7865\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7726 - val_loss: 0.5168 - val_accuracy: 0.7865\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7743 - val_loss: 0.5166 - val_accuracy: 0.7865\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7760 - val_loss: 0.5164 - val_accuracy: 0.7865\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7760 - val_loss: 0.5162 - val_accuracy: 0.7865\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7760 - val_loss: 0.5160 - val_accuracy: 0.7865\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7917\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7917\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7917\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7760 - val_loss: 0.5152 - val_accuracy: 0.7917\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7760 - val_loss: 0.5151 - val_accuracy: 0.7917\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7760 - val_loss: 0.5149 - val_accuracy: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7917\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7917\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7743 - val_loss: 0.5143 - val_accuracy: 0.7917\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7760 - val_loss: 0.5141 - val_accuracy: 0.7917\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7917\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7917\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7917\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7917\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7917\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.7917\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7760 - val_loss: 0.5129 - val_accuracy: 0.7917\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7760 - val_loss: 0.5127 - val_accuracy: 0.7917\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7760 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7917\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7743 - val_loss: 0.5122 - val_accuracy: 0.7969\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7743 - val_loss: 0.5120 - val_accuracy: 0.7969\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7743 - val_loss: 0.5119 - val_accuracy: 0.7969\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7743 - val_loss: 0.5117 - val_accuracy: 0.7969\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7743 - val_loss: 0.5115 - val_accuracy: 0.7969\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7743 - val_loss: 0.5114 - val_accuracy: 0.7917\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7743 - val_loss: 0.5112 - val_accuracy: 0.7917\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7743 - val_loss: 0.5110 - val_accuracy: 0.7917\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7743 - val_loss: 0.5109 - val_accuracy: 0.7917\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7743 - val_loss: 0.5107 - val_accuracy: 0.7917\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7917\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7743 - val_loss: 0.5104 - val_accuracy: 0.7917\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7743 - val_loss: 0.5101 - val_accuracy: 0.7917\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7743 - val_loss: 0.5099 - val_accuracy: 0.7969\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7743 - val_loss: 0.5097 - val_accuracy: 0.7969\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7743 - val_loss: 0.5096 - val_accuracy: 0.7969\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7743 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7969\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7743 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7760 - val_loss: 0.5081 - val_accuracy: 0.7969\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7969\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7778 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7778 - val_loss: 0.5064 - val_accuracy: 0.7969\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7778 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7778 - val_loss: 0.5061 - val_accuracy: 0.7969\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7969\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 0.7969\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7969\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7812 - val_loss: 0.5052 - val_accuracy: 0.7969\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7969\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7795 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7795 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7812 - val_loss: 0.5046 - val_accuracy: 0.7969\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7969\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7812 - val_loss: 0.5044 - val_accuracy: 0.7969\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7812 - val_loss: 0.5043 - val_accuracy: 0.7969\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7969\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7969\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7969\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7969\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7969\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7969\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7969\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7969\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7969\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7969\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7969\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7969\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7969\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7969\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7917\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7917\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7917\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7917\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7917\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7917\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7917\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7917\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7917\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7917\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7917\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7917\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7830 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7865\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7865\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7812 - val_loss: 0.5000 - val_accuracy: 0.7812\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7812\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7812\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7812\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7812\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7812\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7812\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7812\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7812\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7812\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7812\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7812 - val_loss: 0.4989 - val_accuracy: 0.7812\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7812 - val_loss: 0.4988 - val_accuracy: 0.7812\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7812\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7812\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7812\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7812\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7812 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7812 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7812 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7812 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7812 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7812 - val_loss: 0.4977 - val_accuracy: 0.7812\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7812\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7812\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7812\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7830 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7830 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7812 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7812 - val_loss: 0.4958 - val_accuracy: 0.7812\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7830 - val_loss: 0.4957 - val_accuracy: 0.7812\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7812\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7812\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7812\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7812\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7812\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7812\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7812\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7847 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7847 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7847 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7865 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7865 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7812\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7812\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7812\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7812\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7812\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7812\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7812\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4922 - val_accuracy: 0.7812\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4922 - val_accuracy: 0.7812\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7812\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7812\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7812\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7812\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7812\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7812\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7812\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7812\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7812\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7812\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7812\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7760\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7917 - val_loss: 0.4915 - val_accuracy: 0.7760\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7917 - val_loss: 0.4914 - val_accuracy: 0.7760\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7917 - val_loss: 0.4914 - val_accuracy: 0.7760\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7917 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7917 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7917 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7917 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7917 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7917 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7917 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7917 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7917 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7917 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7917 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7917 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7917 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7917 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7917 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7899 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7899 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7882 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7882 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7882 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7882 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7882 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7882 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7882 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7899 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7899 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7708\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7708\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7708\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7708\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7865 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7865 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7865 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7865 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7604\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7604\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7552\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2e7298890a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 accuracy (more interactions) - 0.7552083333333334\n",
      "Model 1 roc-auc_score (more iterations) - 0.8251443383999058\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "print('Model 1 accuracy (more interactions) -',accuracy_score(y_test, y_pred_class_nn_1))\n",
    "print('Model 1 roc-auc_score (more iterations) -',roc_auc_score(y_test, y_pred_prob_nn_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6915 - accuracy: 0.6128 - val_loss: 0.6931 - val_accuracy: 0.6198\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6163 - val_loss: 0.6897 - val_accuracy: 0.6354\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.6198 - val_loss: 0.6865 - val_accuracy: 0.6302\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6233 - val_loss: 0.6833 - val_accuracy: 0.6354\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6354 - val_loss: 0.6802 - val_accuracy: 0.6354\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.6528 - val_loss: 0.6772 - val_accuracy: 0.6354\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6545 - val_loss: 0.6743 - val_accuracy: 0.6406\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6545 - val_loss: 0.6715 - val_accuracy: 0.6406\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6545 - val_loss: 0.6688 - val_accuracy: 0.6406\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6545 - val_loss: 0.6663 - val_accuracy: 0.6406\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6545 - val_loss: 0.6638 - val_accuracy: 0.6406\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6545 - val_loss: 0.6614 - val_accuracy: 0.6406\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6545 - val_loss: 0.6591 - val_accuracy: 0.6406\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6545 - val_loss: 0.6568 - val_accuracy: 0.6406\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6545 - val_loss: 0.6546 - val_accuracy: 0.6406\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6545 - val_loss: 0.6525 - val_accuracy: 0.6406\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.6545 - val_loss: 0.6504 - val_accuracy: 0.6406\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6545 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6545 - val_loss: 0.6464 - val_accuracy: 0.6406\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6545 - val_loss: 0.6445 - val_accuracy: 0.6406\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6545 - val_loss: 0.6427 - val_accuracy: 0.6406\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6545 - val_loss: 0.6409 - val_accuracy: 0.6406\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6545 - val_loss: 0.6391 - val_accuracy: 0.6406\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6545 - val_loss: 0.6374 - val_accuracy: 0.6406\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6545 - val_loss: 0.6358 - val_accuracy: 0.6406\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6545 - val_loss: 0.6341 - val_accuracy: 0.6406\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6545 - val_loss: 0.6326 - val_accuracy: 0.6406\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6545 - val_loss: 0.6310 - val_accuracy: 0.6406\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6545 - val_loss: 0.6295 - val_accuracy: 0.6406\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6545 - val_loss: 0.6280 - val_accuracy: 0.6406\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6545 - val_loss: 0.6265 - val_accuracy: 0.6406\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6545 - val_loss: 0.6251 - val_accuracy: 0.6406\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6545 - val_loss: 0.6237 - val_accuracy: 0.6406\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6545 - val_loss: 0.6224 - val_accuracy: 0.6406\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6545 - val_loss: 0.6210 - val_accuracy: 0.6406\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6545 - val_loss: 0.6197 - val_accuracy: 0.6406\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6545 - val_loss: 0.6185 - val_accuracy: 0.6406\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6545 - val_loss: 0.6172 - val_accuracy: 0.6406\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6545 - val_loss: 0.6159 - val_accuracy: 0.6406\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6545 - val_loss: 0.6146 - val_accuracy: 0.6406\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6545 - val_loss: 0.6134 - val_accuracy: 0.6406\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6545 - val_loss: 0.6122 - val_accuracy: 0.6406\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6545 - val_loss: 0.6110 - val_accuracy: 0.6406\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6545 - val_loss: 0.6099 - val_accuracy: 0.6406\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6545 - val_loss: 0.6087 - val_accuracy: 0.6406\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6545 - val_loss: 0.6076 - val_accuracy: 0.6406\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6545 - val_loss: 0.6065 - val_accuracy: 0.6406\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.6545 - val_loss: 0.6055 - val_accuracy: 0.6406\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6545 - val_loss: 0.6045 - val_accuracy: 0.6406\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.6545 - val_loss: 0.6034 - val_accuracy: 0.6406\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.6545 - val_loss: 0.6024 - val_accuracy: 0.6406\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6545 - val_loss: 0.6014 - val_accuracy: 0.6406\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6545 - val_loss: 0.6005 - val_accuracy: 0.6406\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.6545 - val_loss: 0.5995 - val_accuracy: 0.6406\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.6545 - val_loss: 0.5986 - val_accuracy: 0.6406\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.6545 - val_loss: 0.5977 - val_accuracy: 0.6406\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.6545 - val_loss: 0.5967 - val_accuracy: 0.6406\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.6545 - val_loss: 0.5958 - val_accuracy: 0.6406\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.6545 - val_loss: 0.5949 - val_accuracy: 0.6406\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.6545 - val_loss: 0.5941 - val_accuracy: 0.6406\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.6545 - val_loss: 0.5932 - val_accuracy: 0.6406\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6545 - val_loss: 0.5923 - val_accuracy: 0.6406\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.6545 - val_loss: 0.5915 - val_accuracy: 0.6406\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.6562 - val_loss: 0.5907 - val_accuracy: 0.6406\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.6632 - val_loss: 0.5899 - val_accuracy: 0.6562\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.6753 - val_loss: 0.5891 - val_accuracy: 0.6562\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.6771 - val_loss: 0.5883 - val_accuracy: 0.6562\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.6806 - val_loss: 0.5875 - val_accuracy: 0.6562\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.6788 - val_loss: 0.5868 - val_accuracy: 0.6615\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.6806 - val_loss: 0.5860 - val_accuracy: 0.6615\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.6840 - val_loss: 0.5853 - val_accuracy: 0.6615\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.6858 - val_loss: 0.5845 - val_accuracy: 0.6615\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.6858 - val_loss: 0.5838 - val_accuracy: 0.6615\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.6875 - val_loss: 0.5831 - val_accuracy: 0.6615\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.6910 - val_loss: 0.5824 - val_accuracy: 0.6562\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.6944 - val_loss: 0.5817 - val_accuracy: 0.6615\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.6944 - val_loss: 0.5810 - val_accuracy: 0.6615\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.6979 - val_loss: 0.5804 - val_accuracy: 0.6562\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7014 - val_loss: 0.5797 - val_accuracy: 0.6562\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.6997 - val_loss: 0.5791 - val_accuracy: 0.6667\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7014 - val_loss: 0.5784 - val_accuracy: 0.6667\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7031 - val_loss: 0.5778 - val_accuracy: 0.6667\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7014 - val_loss: 0.5772 - val_accuracy: 0.6667\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7049 - val_loss: 0.5766 - val_accuracy: 0.6562\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7066 - val_loss: 0.5760 - val_accuracy: 0.6562\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7118 - val_loss: 0.5755 - val_accuracy: 0.6562\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7118 - val_loss: 0.5750 - val_accuracy: 0.6562\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7135 - val_loss: 0.5745 - val_accuracy: 0.6562\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7153 - val_loss: 0.5740 - val_accuracy: 0.6562\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7170 - val_loss: 0.5735 - val_accuracy: 0.6562\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7170 - val_loss: 0.5730 - val_accuracy: 0.6562\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7188 - val_loss: 0.5725 - val_accuracy: 0.6562\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7205 - val_loss: 0.5720 - val_accuracy: 0.6562\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7205 - val_loss: 0.5715 - val_accuracy: 0.6615\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7205 - val_loss: 0.5711 - val_accuracy: 0.6667\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7240 - val_loss: 0.5706 - val_accuracy: 0.6719\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7274 - val_loss: 0.5701 - val_accuracy: 0.6719\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7274 - val_loss: 0.5697 - val_accuracy: 0.6667\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7309 - val_loss: 0.5693 - val_accuracy: 0.6667\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7309 - val_loss: 0.5689 - val_accuracy: 0.6667\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7309 - val_loss: 0.5684 - val_accuracy: 0.6719\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7326 - val_loss: 0.5680 - val_accuracy: 0.6719\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7344 - val_loss: 0.5676 - val_accuracy: 0.6719\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7361 - val_loss: 0.5672 - val_accuracy: 0.6719\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7396 - val_loss: 0.5669 - val_accuracy: 0.6771\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7431 - val_loss: 0.5665 - val_accuracy: 0.6771\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7396 - val_loss: 0.5661 - val_accuracy: 0.6823\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7378 - val_loss: 0.5657 - val_accuracy: 0.6823\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7361 - val_loss: 0.5654 - val_accuracy: 0.6823\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7378 - val_loss: 0.5650 - val_accuracy: 0.6771\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7378 - val_loss: 0.5647 - val_accuracy: 0.6823\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7361 - val_loss: 0.5643 - val_accuracy: 0.6927\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7361 - val_loss: 0.5640 - val_accuracy: 0.6927\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7326 - val_loss: 0.5636 - val_accuracy: 0.6927\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7326 - val_loss: 0.5633 - val_accuracy: 0.7031\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7396 - val_loss: 0.5630 - val_accuracy: 0.7031\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7413 - val_loss: 0.5627 - val_accuracy: 0.6979\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7431 - val_loss: 0.5624 - val_accuracy: 0.6979\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7448 - val_loss: 0.5621 - val_accuracy: 0.6927\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7465 - val_loss: 0.5618 - val_accuracy: 0.6979\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7465 - val_loss: 0.5616 - val_accuracy: 0.7031\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7431 - val_loss: 0.5613 - val_accuracy: 0.7083\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7431 - val_loss: 0.5610 - val_accuracy: 0.7135\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7431 - val_loss: 0.5608 - val_accuracy: 0.7135\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7448 - val_loss: 0.5605 - val_accuracy: 0.7135\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7465 - val_loss: 0.5602 - val_accuracy: 0.7135\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7448 - val_loss: 0.5600 - val_accuracy: 0.7135\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7431 - val_loss: 0.5597 - val_accuracy: 0.7135\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7448 - val_loss: 0.5595 - val_accuracy: 0.7135\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7448 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7465 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7465 - val_loss: 0.5588 - val_accuracy: 0.7083\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7483 - val_loss: 0.5586 - val_accuracy: 0.7135\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7483 - val_loss: 0.5584 - val_accuracy: 0.7135\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7500 - val_loss: 0.5581 - val_accuracy: 0.7135\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7483 - val_loss: 0.5579 - val_accuracy: 0.7135\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7483 - val_loss: 0.5577 - val_accuracy: 0.7135\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7500 - val_loss: 0.5575 - val_accuracy: 0.7240\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7535 - val_loss: 0.5573 - val_accuracy: 0.7240\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7569 - val_loss: 0.5571 - val_accuracy: 0.7292\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7569 - val_loss: 0.5569 - val_accuracy: 0.7396\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7587 - val_loss: 0.5567 - val_accuracy: 0.7396\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7587 - val_loss: 0.5565 - val_accuracy: 0.7396\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7604 - val_loss: 0.5563 - val_accuracy: 0.7396\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7604 - val_loss: 0.5562 - val_accuracy: 0.7396\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7622 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7396\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7622 - val_loss: 0.5556 - val_accuracy: 0.7344\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7656 - val_loss: 0.5555 - val_accuracy: 0.7292\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7656 - val_loss: 0.5553 - val_accuracy: 0.7292\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7656 - val_loss: 0.5551 - val_accuracy: 0.7344\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7656 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5548 - val_accuracy: 0.7344\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7639 - val_loss: 0.5547 - val_accuracy: 0.7344\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7622 - val_loss: 0.5545 - val_accuracy: 0.7344\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7639 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7656 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7639 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7639 - val_loss: 0.5540 - val_accuracy: 0.7344\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7639 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7674 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7674 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7674 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7691 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7691 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7708 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7708 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7708 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7726 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7708 - val_loss: 0.5525 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7726 - val_loss: 0.5524 - val_accuracy: 0.7448\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7743 - val_loss: 0.5523 - val_accuracy: 0.7448\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7743 - val_loss: 0.5522 - val_accuracy: 0.7448\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7795 - val_loss: 0.5520 - val_accuracy: 0.7448\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7778 - val_loss: 0.5519 - val_accuracy: 0.7448\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7812 - val_loss: 0.5518 - val_accuracy: 0.7448\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7830 - val_loss: 0.5517 - val_accuracy: 0.7448\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7847 - val_loss: 0.5516 - val_accuracy: 0.7500\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7847 - val_loss: 0.5515 - val_accuracy: 0.7552\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7847 - val_loss: 0.5514 - val_accuracy: 0.7604\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7847 - val_loss: 0.5513 - val_accuracy: 0.7604\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7847 - val_loss: 0.5512 - val_accuracy: 0.7604\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7847 - val_loss: 0.5510 - val_accuracy: 0.7604\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7830 - val_loss: 0.5509 - val_accuracy: 0.7604\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7812 - val_loss: 0.5508 - val_accuracy: 0.7604\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7795 - val_loss: 0.5507 - val_accuracy: 0.7604\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7795 - val_loss: 0.5506 - val_accuracy: 0.7604\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7812 - val_loss: 0.5505 - val_accuracy: 0.7604\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7795 - val_loss: 0.5504 - val_accuracy: 0.7604\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7812 - val_loss: 0.5503 - val_accuracy: 0.7656\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7812 - val_loss: 0.5502 - val_accuracy: 0.7656\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7812 - val_loss: 0.5501 - val_accuracy: 0.7656\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7812 - val_loss: 0.5501 - val_accuracy: 0.7656\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7812 - val_loss: 0.5500 - val_accuracy: 0.7656\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7812 - val_loss: 0.5499 - val_accuracy: 0.7656\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7795 - val_loss: 0.5498 - val_accuracy: 0.7656\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7795 - val_loss: 0.5497 - val_accuracy: 0.7656\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7795 - val_loss: 0.5497 - val_accuracy: 0.7656\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7795 - val_loss: 0.5496 - val_accuracy: 0.7656\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7812 - val_loss: 0.5495 - val_accuracy: 0.7656\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7795 - val_loss: 0.5494 - val_accuracy: 0.7656\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7795 - val_loss: 0.5494 - val_accuracy: 0.7656\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7795 - val_loss: 0.5493 - val_accuracy: 0.7656\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7795 - val_loss: 0.5492 - val_accuracy: 0.7604\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7778 - val_loss: 0.5492 - val_accuracy: 0.7604\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.59 - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7778 - val_loss: 0.5491 - val_accuracy: 0.7604\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7778 - val_loss: 0.5490 - val_accuracy: 0.7604\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7778 - val_loss: 0.5490 - val_accuracy: 0.7604\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.5489 - val_accuracy: 0.7656\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7778 - val_loss: 0.5489 - val_accuracy: 0.7656\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7778 - val_loss: 0.5488 - val_accuracy: 0.7656\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7778 - val_loss: 0.5487 - val_accuracy: 0.7656\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7795 - val_loss: 0.5487 - val_accuracy: 0.7656\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7778 - val_loss: 0.5486 - val_accuracy: 0.7656\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.5486 - val_accuracy: 0.7656\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.5485 - val_accuracy: 0.7656\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.5485 - val_accuracy: 0.7656\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7760 - val_loss: 0.5484 - val_accuracy: 0.7656\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.5484 - val_accuracy: 0.7656\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7760 - val_loss: 0.5483 - val_accuracy: 0.7656\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.5483 - val_accuracy: 0.7656\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.5482 - val_accuracy: 0.7656\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7778 - val_loss: 0.5482 - val_accuracy: 0.7656\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7795 - val_loss: 0.5481 - val_accuracy: 0.7656\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7795 - val_loss: 0.5481 - val_accuracy: 0.7708\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7795 - val_loss: 0.5480 - val_accuracy: 0.7708\n",
      "Epoch 228/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.5480 - val_accuracy: 0.7708\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7830 - val_loss: 0.5479 - val_accuracy: 0.7708\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7812 - val_loss: 0.5479 - val_accuracy: 0.7708\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.5479 - val_accuracy: 0.7708\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.5478 - val_accuracy: 0.7708\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7795 - val_loss: 0.5478 - val_accuracy: 0.7708\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5478 - val_accuracy: 0.7708\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5477 - val_accuracy: 0.7708\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.5477 - val_accuracy: 0.7708\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5477 - val_accuracy: 0.7708\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.5476 - val_accuracy: 0.7708\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5476 - val_accuracy: 0.7708\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5476 - val_accuracy: 0.7708\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5475 - val_accuracy: 0.7708\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5475 - val_accuracy: 0.7708\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.5475 - val_accuracy: 0.7708\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7760 - val_loss: 0.5475 - val_accuracy: 0.7656\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.5474 - val_accuracy: 0.7656\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.5474 - val_accuracy: 0.7656\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.5474 - val_accuracy: 0.7656\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.5474 - val_accuracy: 0.7604\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.5474 - val_accuracy: 0.7604\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7760 - val_loss: 0.5473 - val_accuracy: 0.7604\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.5473 - val_accuracy: 0.7604\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.5473 - val_accuracy: 0.7604\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.5473 - val_accuracy: 0.7604\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7760 - val_loss: 0.5473 - val_accuracy: 0.7604\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.5472 - val_accuracy: 0.7604\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.5472 - val_accuracy: 0.7604\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7760 - val_loss: 0.5472 - val_accuracy: 0.7604\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7760 - val_loss: 0.5472 - val_accuracy: 0.7656\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.5471 - val_accuracy: 0.7656\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.5471 - val_accuracy: 0.7656\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.5471 - val_accuracy: 0.7656\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.5471 - val_accuracy: 0.7656\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7760 - val_loss: 0.5471 - val_accuracy: 0.7656\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.5471 - val_accuracy: 0.7656\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.5470 - val_accuracy: 0.7656\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7743 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7743 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.5469 - val_accuracy: 0.7604\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.5468 - val_accuracy: 0.7604\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.5468 - val_accuracy: 0.7604\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.5468 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.5468 - val_accuracy: 0.7604\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.5468 - val_accuracy: 0.7604\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.5468 - val_accuracy: 0.7604\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.5467 - val_accuracy: 0.7604\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.5467 - val_accuracy: 0.7604\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.5467 - val_accuracy: 0.7604\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5467 - val_accuracy: 0.7604\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.5466 - val_accuracy: 0.7604\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.5466 - val_accuracy: 0.7604\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5466 - val_accuracy: 0.7604\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.5465 - val_accuracy: 0.7604\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5465 - val_accuracy: 0.7604\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5465 - val_accuracy: 0.7604\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.5465 - val_accuracy: 0.7604\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.5464 - val_accuracy: 0.7604\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.5464 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5463 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.5463 - val_accuracy: 0.7604\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.5462 - val_accuracy: 0.7552\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.5462 - val_accuracy: 0.7552\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.5462 - val_accuracy: 0.7552\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.5461 - val_accuracy: 0.7552\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.5461 - val_accuracy: 0.7552\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.5460 - val_accuracy: 0.7552\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.5460 - val_accuracy: 0.7552\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.5459 - val_accuracy: 0.7552\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7552\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7552\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7847 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7830 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7830 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7830 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7830 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7830 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7830 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7830 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.5439 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.5437 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.5436 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7830 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7847 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7865 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.5414 - val_accuracy: 0.7552\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7865 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.5411 - val_accuracy: 0.7552\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.5410 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7865 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7847 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7865 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7865 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7865 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7865 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7865 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.5398 - val_accuracy: 0.7552\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.5398 - val_accuracy: 0.7552\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.5393 - val_accuracy: 0.7552\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5392 - val_accuracy: 0.7552\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.5390 - val_accuracy: 0.7552\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7882 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.5388 - val_accuracy: 0.7552\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.5387 - val_accuracy: 0.7552\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7865 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7865 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7865 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7865 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7865 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.5381 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.5368 - val_accuracy: 0.7448\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.5368 - val_accuracy: 0.7448\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.5367 - val_accuracy: 0.7448\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.5366 - val_accuracy: 0.7448\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5366 - val_accuracy: 0.7448\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5365 - val_accuracy: 0.7448\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.5364 - val_accuracy: 0.7448\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5364 - val_accuracy: 0.7448\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5361 - val_accuracy: 0.7448\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.5361 - val_accuracy: 0.7448\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.5360 - val_accuracy: 0.7448\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.5360 - val_accuracy: 0.7448\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7448\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5359 - val_accuracy: 0.7448\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5353 - val_accuracy: 0.7448\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5353 - val_accuracy: 0.7448\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7865 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7865 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7865 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7865 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7865 - val_loss: 0.5347 - val_accuracy: 0.7448\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7865 - val_loss: 0.5347 - val_accuracy: 0.7448\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5345 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5342 - val_accuracy: 0.7448\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7830 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7830 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5313 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7865 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7396\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7396\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7396\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7396\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.5286 - val_accuracy: 0.7396\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.5286 - val_accuracy: 0.7396\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7396\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7396\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.5280 - val_accuracy: 0.7396\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7865 - val_loss: 0.5280 - val_accuracy: 0.7396\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7865 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7865 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5277 - val_accuracy: 0.7396\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.5276 - val_accuracy: 0.7396\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.5276 - val_accuracy: 0.7396\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5275 - val_accuracy: 0.7396\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7396\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7344\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7344\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5273 - val_accuracy: 0.7344\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5272 - val_accuracy: 0.7344\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5272 - val_accuracy: 0.7344\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7344\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5270 - val_accuracy: 0.7344\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7882 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5268 - val_accuracy: 0.7344\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7899 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5261 - val_accuracy: 0.7344\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5261 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5261 - val_accuracy: 0.7344\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7899 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5257 - val_accuracy: 0.7344\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7899 - val_loss: 0.5257 - val_accuracy: 0.7344\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5257 - val_accuracy: 0.7344\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7899 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7917 - val_loss: 0.5254 - val_accuracy: 0.7344\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5254 - val_accuracy: 0.7344\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5254 - val_accuracy: 0.7344\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7899 - val_loss: 0.5254 - val_accuracy: 0.7344\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7899 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7899 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7899 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5247 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7847 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7847 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7847 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7847 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7847 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5241 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7812 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7847 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7847 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7847 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7812 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7812 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7830 - val_loss: 0.5229 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7795 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7795 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7795 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7812 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7812 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7812 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7812 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7812 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7812 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7812 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7812 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7812 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7812 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7812 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7830 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7830 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7830 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7830 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7830 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7847 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7847 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7847 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7847 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7847 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7847 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7865 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7865 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7865 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7865 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1138/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7882 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7882 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7882 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7882 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7882 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7882 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7899 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7882 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.84 - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 1194/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7917 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7917 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7899 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1306/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7917 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1362/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1418/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1474/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7951 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7951 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.734\n",
      "roc-auc is 0.819\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
